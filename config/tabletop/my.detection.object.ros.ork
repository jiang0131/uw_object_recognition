source1:
  type: RosKinect
  module: 'object_recognition_ros.io'
  #
  # Example parameters to set (the default settings are using the ros topics starting with /camera/....) 
  #  
  parameters:
    rgb_frame_id: head_mount_kinect_rgb_optical_frame
    rgb_image_topic: /head_mount_kinect/rgb/image_rect_color
    rgb_camera_info: /head_mount_kinect/rgb/camera_info
    depth_image_topic: /head_mount_kinect/depth_registered/hw_registered/image_rect_raw
    depth_camera_info: /head_mount_kinect/depth_registered/camera_info
    #crop_enabled: True
    #x_min: -0.4
    #x_max: 0.4
    #y_min: -1.0
    #y_max: 0.2
    #z_min: 0.3
    #z_max: 1.5
  
sink1:
  type: TablePublisher
  module: 'object_recognition_tabletop.table_publisher'
  inputs: [source1]

sink2:
  type: ClusterPublisher
  module: 'object_recognition_tabletop.cluster_publisher'
  inputs: [source1]
  parameters:
    latched: True
    tabletop_cluster_topic: tabletop_cluster

sink3:
  type: Publisher
  #module: 'object_recognition_ros.io.sink.publisher'
  module: 'object_recognition_ros.io'
  inputs: [source1]
  parameters:
    #do_visualize: True
    latched: True
    #  The ROS topic to use for the marker array.
    markers_topic: markers
    #  The ROS topic to use for the object meta info string
    object_ids_topic: object_ids
    #  The ROS topic to use for the pose array.
    pose_topic: object_poses
    #  Sets whether the point cloud clusters have to be published or not
    publish_clusters: True
    #  The ROS topic to use for the recognized object
    recognized_object_array_topic: recognized_object_array

pipeline1:
  type: TabletopTableDetector
  module: 'object_recognition_tabletop'
  inputs: [source1]
  outputs: [sink1, sink2]
  parameters:
    table_detector:
        min_table_size: 20000
        plane_threshold: 0.01
    #clusterer:
        #table_z_filter_max: 1.0
        #table_z_filter_min: 0.40
        #table_z_filter_max: 0.35
        #table_z_filter_min: 0.025

pipeline2:
  type: TabletopObjectDetector
  module: 'object_recognition_tabletop.detector'
  inputs: [pipeline1]
  outputs: [sink3]
  parameters:
    db:
      type: 'CouchDB'
      root: 'http://localhost:5984'
      collection: 'object_recognition'
    # The list of object_ids to analyze
    object_ids: "all"
